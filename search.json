[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "EuroFab research project",
    "section": "",
    "text": "The landing page of the EuroFab project."
  },
  {
    "objectID": "notebooks/hilbert_split.html",
    "href": "notebooks/hilbert_split.html",
    "title": "Hilbert distance-based split into train and test",
    "section": "",
    "text": "This notebook illustrates the core of the approach to split chips into train and test used in the CEUS paper. There it was a bit more complicated than that but the principle is illustrated here.\n\nimport geopandas as gpd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom shapely import box\n\nGet only a subset of the country for illustration - NW.\n\nstart_x, start_y, end_x, end_y = (321566, 365379, 468106, 437198)\n\nLoad the data and clip them to the box defined above. The data from https://figshare.com/ndownloader/files/38736501\n\nsignatures  = gpd.read_file(\"/Users/martin/Downloads/spatial_signatures_GB_simplified.gpkg\", bbox=(start_x, start_y, end_x, end_y)).clip(box(start_x, start_y, end_x, end_y))\n\nGet coordinates of chip centroids.\n\nx_coords = np.arange(start_x, end_x, 250)\ny_coords = np.arange(start_y, end_y, 250)\nxv, yv = np.meshgrid(x_coords, y_coords)\ncombinations = np.vstack([xv.ravel(), yv.ravel()])\n\nGet chip geoemtry.\n\ngrid_cells = gpd.GeoSeries.from_xy(x=combinations[0], y=combinations[1], crs=signatures.crs).buffer(125, cap_style=3)\n\nFilter only those fully within signatures.\n\nsig_idx, grid_idx = grid_cells.sindex.query(signatures.geometry, predicate=\"contains\")\nvalid_grid_cells = grid_cells.iloc[grid_idx].to_frame('geometry')\nvalid_grid_cells[\"sig_id\"] = sig_idx\n\nGet unique signature IDs to pull from.\n\nunique = valid_grid_cells.sig_id.unique()\nunique.shape[0]\n\n745\n\n\nIllustrate the split using Hilbert distance. Chip groups with less than 20 chips are not split and should be allocated together either to train or test. The distance itself could be retrieved via GeoSeries.hilbert_distance() if needed.\n\ng = valid_grid_cells[valid_grid_cells.sig_id == unique[79]]\nif g.shape[0] &gt; 20:\n    split = np.empty(g.shape[0], dtype=int)\n    floor = int(np.floor(g.shape[0] * 0.8))\n    split[:floor] = 0\n    split[floor:] = 1\nelse:\n    split = np.ones(g.shape[0])\n\nf, ax = plt.subplots(1, 2, sharey=True)\ng.sort_values(\"geometry\").plot(split, ax=ax[0])\ng.sort_values(\"geometry\").plot(cmap=\"viridis\", ax=ax[1])\nax[0].set_title(\"split\")\nax[1].set_title(\"hilbert distance\")\n\nText(0.5, 1.0, 'hilbert distance')"
  },
  {
    "objectID": "notebooks/run_pipeline.html",
    "href": "notebooks/run_pipeline.html",
    "title": "Earth observation | EuroFab",
    "section": "",
    "text": "import sys\nsys.path.insert(1, '/bask/homes/f/fedu7800/vjgo8416-demoland/spatial_signatures/eo/ai_pipeline')\n\nimport pandas as pd\nimport pipeline\nfrom pipeline import GeoTileDataset, read_data, plot_examples\n\nfrom torch.utils.data import Dataset, DataLoader\nimport matplotlib.pyplot as plt\nimport geopandas as gpd\n\n%matplotlib inline\n\n\ngeojson_path = '/bask/homes/f/fedu7800/vjgo8416-demoland/spatial_signatures/eo/data/example/london_25_25_grid_clipped.geojson'\n#geojson_path = '/bask/homes/f/fedu7800/vjgo8416-demoland/spatial_signatures/eo/data/example/liverpool_25_25_grid_clipped.geojson'\n\nvrt_file = '/bask/homes/f/fedu7800/vjgo8416-demoland/satellite_demoland/data/mosaic_cube/vrt_allbands/2017_combined.vrt'\n\n\n#The function read_data(geojson_path, vrt_file) initialises a custom geospatial dataset and prepares a dataloader for batch processing.\ndataset, dataloader = read_data(geojson_path, vrt_file)\n\n\n#The function plot_examples(dataset, num_examples=n) is used to visualise example image tiles from the dataset. \n#This helps in verifying the quality and preprocessing of the satellite imagery before using it in a model.\nplot_examples(dataset, num_examples=3)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Run the pipeline\npipeline.spatial_sig_prediction(\n    geo_path= \"/bask/homes/f/fedu7800/vjgo8416-demoland/spatial_signatures/eo/data/example/london_25_25_grid_clipped.geojson\",\n    vrt_file= \"/bask/homes/f/fedu7800/vjgo8416-demoland/satellite_demoland/data/mosaic_cube/vrt_allbands/2017_combined.vrt\",\n    xgb_weights = \"/bask/homes/f/fedu7800/vjgo8416-demoland/spatial_signatures/eo/data/weights/xgb_model_25_latlonh6_feb25_weighted.bin\",\n    model_weights = \"/bask/homes/f/fedu7800/vjgo8416-demoland/satellite_demoland/models/satlas/weights/satlas-model-v1-lowres.pth\",\n    output_path= \"/bask/homes/f/fedu7800/vjgo8416-demoland/spatial_signatures/eo/data/predictions/test_london_h6.parquet\",\n    h3_resolution=6\n)\n\n\n# Run the pipeline\npipeline.spatial_sig_prediction(\n    geo_path= \"/bask/homes/f/fedu7800/vjgo8416-demoland/spatial_signatures/eo/data/example/london_25_25_grid_clipped.geojson\",\n    vrt_file= \"/bask/homes/f/fedu7800/vjgo8416-demoland/satellite_demoland/data/mosaic_cube/vrt_allbands/2017_combined.vrt\",\n    xgb_weights = \"/bask/homes/f/fedu7800/vjgo8416-demoland/spatial_signatures/predictions/xgb_model_25_k7_latlonh0_feb25_weighted.bin\",\n    model_weights = \"/bask/homes/f/fedu7800/vjgo8416-demoland/satellite_demoland/models/satlas/weights/satlas-model-v1-lowres.pth\",\n    output_path= \"/bask/homes/f/fedu7800/vjgo8416-demoland/spatial_signatures/eo/data/predictions/test_london_h0.parquet\",\n    h3_resolution=0\n)\n\n\n# Run the pipeline\npipeline.spatial_sig_prediction(\n    geo_path= \"/bask/homes/f/fedu7800/vjgo8416-demoland/spatial_signatures/eo/data/example/london_25_25_grid_clipped.geojson\",\n    vrt_file= \"/bask/homes/f/fedu7800/vjgo8416-demoland/satellite_demoland/data/mosaic_cube/vrt_allbands/2017_combined.vrt\",\n    xgb_weights = \"/bask/homes/f/fedu7800/vjgo8416-demoland/spatial_signatures/predictions/xgb_model_25_k7_latlonh5_feb25_weighted.bin\",\n    model_weights = \"/bask/homes/f/fedu7800/vjgo8416-demoland/satellite_demoland/models/satlas/weights/satlas-model-v1-lowres.pth\",\n    output_path= \"/bask/homes/f/fedu7800/vjgo8416-demoland/spatial_signatures/eo/data/predictions/test_london_h5.parquet\",\n    h3_resolution=5\n)\n\n\ntest = gpd.read_parquet('/bask/homes/f/fedu7800/vjgo8416-demoland/spatial_signatures/eo/data/predictions/test_london_h5.parquet')\n\n\nclass_labels_k7 = {'Countryside agriculture': 0, 'Open sprawl': 1, 'Other': 2, 'Urban': 3, 'Urban buffer': 4, 'Warehouse/Park land': 5, 'Wild countryside': 6}\n\n\nclass_labels = {\n    'Accessible suburbia': 0,\n    'Connected residential neighbourhoods': 1,\n    'Countryside agriculture': 2,\n    'Dense residential neighbourhoods': 3,\n    'Dense urban neighbourhoods': 4,\n    'Disconnected suburbia': 5,\n    'Gridded residential quarters': 6,\n    'Open sprawl': 7,\n    'Urban buffer': 8,\n    'Urbanity': 9,\n    'Warehouse/Park land': 10,\n    'Wild countryside': 11\n}\n\n\ntest['class'] = test['prediction'].map({v: k for k, v in class_labels_k7.items()})\n\n\ntest.explore(column='class', cmap='Accent')\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\n\ntest.explore(column='class', cmap='Accent')\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\n\n# Run the pipeline\npipeline.spatial_sig_prediction(\n    #geo_path= \"/bask/homes/f/fedu7800/vjgo8416-demoland/spatial_signatures/agri_grid_example.geojson\", #/eo/data/example/liverpool_25_25_grid_clipped.geojson\",\n    geo_path= \"/bask/homes/f/fedu7800/vjgo8416-demoland/spatial_signatures/eo/data/example/liverpool_25_25_grid_clipped.geojson\",\n    vrt_file= \"/bask/homes/f/fedu7800/vjgo8416-demoland/satellite_demoland/data/mosaic_cube/vrt_allbands/2017_combined.vrt\",\n    xgb_weights = \"/bask/homes/f/fedu7800/vjgo8416-demoland/spatial_signatures/predictions/xgb_model_25_k7_latlonh5_feb25_weighted.bin\",\n    model_weights = \"/bask/homes/f/fedu7800/vjgo8416-demoland/satellite_demoland/models/satlas/weights/satlas-model-v1-lowres.pth\",\n    output_path= \"/bask/homes/f/fedu7800/vjgo8416-demoland/spatial_signatures/eo/data/predictions/test_liverpool_h5.parquet\",\n    h3_resolution=5\n)\n\n\ntest2 = gpd.read_parquet('/bask/homes/f/fedu7800/vjgo8416-demoland/spatial_signatures/eo/data/predictions/test_liverpool_h5.parquet')# #test_liverpool_h0.parquet')\n\n\ntest2['class'] = test2['prediction'].map({v: k for k, v in class_labels_k7.items()})\n\n\ntest2.explore(column='class', cmap='tab20')\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\n\ntest2.explore(column='class', cmap='tab20')\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\n\ntest2.explore(column='class', cmap='tab20')\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\n\ntest2.explore(column='class', cmap='tab20')\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook"
  },
  {
    "objectID": "notebooks/hello.html",
    "href": "notebooks/hello.html",
    "title": "Example notebook",
    "section": "",
    "text": "These should not be executed by Quarto.\n\nimport geopandas\n\ngeopandas.show_versions()\n\n\nSYSTEM INFO\n-----------\npython     : 3.11.4 | packaged by conda-forge | (main, Jun 10 2023, 18:08:41) [Clang 15.0.7 ]\nexecutable : /Users/martin/miniforge3/envs/stable/bin/python\nmachine    : macOS-14.5-arm64-arm-64bit\n\nGEOS, GDAL, PROJ INFO\n---------------------\nGEOS       : 3.12.1\nGEOS lib   : None\nGDAL       : 3.7.3\nGDAL data dir: /Users/martin/miniforge3/envs/stable/share/gdal\nPROJ       : 9.3.0\nPROJ data dir: /Users/martin/miniforge3/envs/stable/share/proj\n\nPYTHON DEPENDENCIES\n-------------------\ngeopandas  : 0.14.4\nnumpy      : 1.26.4\npandas     : 2.2.2\npyproj     : 3.6.1\nshapely    : 2.0.4\nfiona      : 1.9.5\ngeoalchemy2: None\ngeopy      : 2.4.1\nmatplotlib : 3.8.4\nmapclassify: 2.6.1\npygeos     : None\npyogrio    : 0.7.2\npsycopg2   : None\npyarrow    : 16.1.0\nrtree      : 1.2.0",
    "crumbs": [
      "Notebooks",
      "Example notebook"
    ]
  },
  {
    "objectID": "notebooks/simulated_annealing.html",
    "href": "notebooks/simulated_annealing.html",
    "title": "Earth observation | EuroFab",
    "section": "",
    "text": "import numpy as np\nimport pandas as pd\nfrom numba import njit\n\nimport urbangrammar_graphics as ugg\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n%matplotlib inline\n\n\n# Generate a random 12x12 confusion matrix with integer values\nnp.random.seed(42)  # For reproducibility\nconf_matrix = np.random.randint(0, 100, size=(12, 12))\n\n# Define class labels\nclass_dict = {\n    'Accessible suburbia': 0,\n    'Connected residential neighbourhoods': 1,\n    'Countryside agriculture': 2,\n    'Dense residential neighbourhoods': 3,\n    'Dense urban neighbourhoods': 4,\n    'Disconnected suburbia': 5,\n    'Gridded residential quarters': 6,\n    'Open sprawl': 7,\n    'Urban buffer': 8,\n    'Urbanity': 9,\n    'Warehouse/Park land': 10,\n    'Wild countryside': 11\n}\n\n# Reverse lookup for labels\nclass_labels = {v: k for k, v in class_dict.items()}\n\n# Plot the heatmap\nplt.figure(figsize=(10, 8))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap=sns.light_palette(ugg.HEX[1], n_colors=100), xticklabels=class_labels, yticklabels=class_labels)\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.title(\"12x12 Confusion Matrix\")\nplt.show()\n\n\n\n\n\n\n\n\n\n@njit\ndef nscore(a):\n    ds = []\n    r = range(len(a))\n    for i in r:\n        for j in r:\n            if a[i, j] != 0:\n                ds.append(abs(i-j))\n    return np.array(ds).mean()\n\n@njit\ndef wnscore(a):\n    ds = []\n    r = range(len(a))\n    total = a.sum()\n    for i in r:\n        for j in r:\n            aij = a[i, j]\n            if aij != 0:\n                ds.append(abs(i-j) * aij / total)\n    return np.array(ds).mean()\n\n\n\n#Bit hacky but fast(er) sorting algorithm that doesn't use all permutations (which takes more than 1h for a 12x12 grid).\ndef simulated_annealing(a, w=True, max_iters=500000, temp=1.0, cooling_rate=0.995):\n    \"\"\"\n    Optimizes the row/column order using simulated annealing.\n    \n    Args:\n        a: The 2D numpy array.\n        w: Whether to use weighted nscore.\n        max_iters: Maximum number of iterations.\n        temp: Initial temperature for annealing.\n        cooling_rate: Decay rate for temperature.\n\n    Returns:\n        The best found permutation.\n    \"\"\"\n    if w:\n        scorer = wnscore\n    else:\n        scorer = nscore\n\n    la = len(a)\n    \n    # Initial permutation (sorted by row sums as a heuristic)\n    current_perm = np.argsort(a.sum(axis=1))\n    best_perm = current_perm.copy()\n    best_score = scorer(a[current_perm, :][:, current_perm])\n\n    for _ in range(max_iters):\n        temp *= cooling_rate  # Reduce temperature\n\n        # Swap two random indices\n        new_perm = current_perm.copy()\n        i, j = np.random.choice(la, 2, replace=False)\n        new_perm[i], new_perm[j] = new_perm[j], new_perm[i]\n\n        # Compute new score\n        new_score = scorer(a[new_perm, :][:, new_perm])\n        \n        # Accept new permutation if it's better or with a probability\n        if new_score &lt; best_score or np.exp((best_score - new_score) / temp) &gt; np.random.rand():\n            current_perm = new_perm\n            best_score = new_score\n            best_perm = new_perm\n\n        # Stop early if temperature is too low\n        if temp &lt; 1e-6:\n            break\n\n    return best_perm\n\n\n#cols = list(class_labels.values())  # Get class labels as list\ncols = list(range(0,12))\ntab = pd.DataFrame(conf_matrix)  # Copy the transition matrix\n\n# ensure column names match correctly\n#cols = [i.strip() for i in cols]  # Remove any unwanted spaces\nstab = tab.loc[cols, cols]  # Reorder based on labels\n\n# remove the diagonal\nstab_no_diag = stab.copy()\nnp.fill_diagonal(stab_no_diag.values, 0)  # Set diagonal to zero\n\n# Sorting\norder = simulated_annealing(stab_no_diag.values, w=False)  # Unweighted score sorting\nweighted_order = simulated_annealing(stab_no_diag.values, w=True)  # Weighted score sorting\n\nstab_sorted = stab.iloc[order, order]  # Reorder rows and columns\n\n\nplt.figure(figsize=(10, 8))\n\n# Plot heatmap\nsns.heatmap((stab_no_diag.iloc[weighted_order, weighted_order]).replace(0, np.nan).astype('float'), \n            cmap=sns.light_palette(ugg.HEX[1], n_colors=100),\n            annot=True)\n\n# Show plot\nplt.show()"
  },
  {
    "objectID": "notebooks/matrix_sorting.html",
    "href": "notebooks/matrix_sorting.html",
    "title": "Sorting based on co-occurence",
    "section": "",
    "text": "import pandas\n\nGet co-occurence table\n\n# https://urbangrammarai.xyz/spatial_signatures/esda/co-occurence.html\ntab = \"\"\"\nneighbor_type   Countryside agriculture     Accessible suburbia     Dense residential neighbourhoods    Connected residential neighbourhoods    Dense urban neighbourhoods  Open sprawl     Wild countryside    Warehouse/Park land     Gridded residential quarters    Urban buffer    Disconnected suburbia   Local urbanity  Concentrated urbanity   Regional urbanity   Metropolitan urbanity   Hyper concentrated urbanity\nCountryside agriculture     0   6   0   3   0   11  7323    181     1   14659   0   3   0   0   3   0\nAccessible suburbia     6   0   2710    3573    2   13403   6   2068    1079    4070    3423    0   0   0   0   0\nDense residential neighbourhoods    0   2710    0   4622    3457    3450    0   3632    1246    25  1600    1   0   0   0   0\nConnected residential neighbourhoods    3   3573    4622    0   1012    1222    1   2163    1939    35  1508    2   0   1   0   0\nDense urban neighbourhoods  0   2   3457    1012    0   5   0   414     443     1   52  1603    0   0   0   0\nOpen sprawl     11  13403   3450    1222    5   0   2   10383   660     14793   9521    0   0   0   0   0\nWild countryside    7323    6   0   1   0   2   0   0   2   48  0   4   0   0   1   0\nWarehouse/Park land     181     2068    3632    2163    414     10383   0   0   73  4837    3313    30  0   0   0   0\nGridded residential quarters    1   1079    1246    1939    443     660     2   73  0   16  273     133     0   0   0   0\nUrban buffer    14659   4070    25  35  1   14793   48  4837    16  0   420     3   0   0   1   0\nDisconnected suburbia   0   3423    1600    1508    52  9521    0   3313    273     420     0   0   0   1   0   0\nLocal urbanity  3   0   1   2   1603    0   4   30  133     3   0   0   0   341     1   0\nConcentrated urbanity   0   0   0   0   0   0   0   0   0   0   0   0   0   0   12  5\nRegional urbanity   0   0   0   1   0   0   0   0   0   0   1   341     0   0   133     0\nMetropolitan urbanity   3   0   0   0   0   0   1   0   0   1   0   1   12  133     0   0\nHyper concentrated urbanity     0   0   0   0   0   0   0   0   0   0   0   0   5   0   0   0\n\"\"\"\nfrom io import StringIO\ntab = pandas.read_table(StringIO(tab), index_col='neighbor_type ')\ntab = (\n    tab\n    .divide(tab.sum(axis=1), axis=0)\n    .round(2)\n    #.replace(0, numpy.nan)\n    .astype('float')\n    * 100\n)\ntab.index = [i.strip(' ') for i in tab.index]\ntab.columns =[i.strip(' ') for i in tab.columns]\n\n\ntab\n\n\n\n\n\n\n\n\nCountryside agriculture\nAccessible suburbia\nDense residential neighbourhoods\nConnected residential neighbourhoods\nDense urban neighbourhoods\nOpen sprawl\nWild countryside\nWarehouse/Park land\nGridded residential quarters\nUrban buffer\nDisconnected suburbia\nLocal urbanity\nConcentrated urbanity\nRegional urbanity\nMetropolitan urbanity\nHyper concentrated urbanity\n\n\n\n\nCountryside agriculture\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n33.0\n1.0\n0.0\n66.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\nAccessible suburbia\n0.0\n0.0\n9.0\n12.0\n0.0\n44.0\n0.0\n7.0\n4.0\n13.0\n11.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\nDense residential neighbourhoods\n0.0\n13.0\n0.0\n22.0\n17.0\n17.0\n0.0\n18.0\n6.0\n0.0\n8.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\nConnected residential neighbourhoods\n0.0\n22.0\n29.0\n0.0\n6.0\n8.0\n0.0\n13.0\n12.0\n0.0\n9.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\nDense urban neighbourhoods\n0.0\n0.0\n49.0\n14.0\n0.0\n0.0\n0.0\n6.0\n6.0\n0.0\n1.0\n23.0\n0.0\n0.0\n0.0\n0.0\n\n\nOpen sprawl\n0.0\n25.0\n6.0\n2.0\n0.0\n0.0\n0.0\n19.0\n1.0\n28.0\n18.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\nWild countryside\n99.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n1.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\nWarehouse/Park land\n1.0\n8.0\n13.0\n8.0\n2.0\n38.0\n0.0\n0.0\n0.0\n18.0\n12.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\nGridded residential quarters\n0.0\n18.0\n21.0\n33.0\n8.0\n11.0\n0.0\n1.0\n0.0\n0.0\n5.0\n2.0\n0.0\n0.0\n0.0\n0.0\n\n\nUrban buffer\n38.0\n10.0\n0.0\n0.0\n0.0\n38.0\n0.0\n12.0\n0.0\n0.0\n1.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\nDisconnected suburbia\n0.0\n17.0\n8.0\n7.0\n0.0\n47.0\n0.0\n16.0\n1.0\n2.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\nLocal urbanity\n0.0\n0.0\n0.0\n0.0\n76.0\n0.0\n0.0\n1.0\n6.0\n0.0\n0.0\n0.0\n0.0\n16.0\n0.0\n0.0\n\n\nConcentrated urbanity\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n71.0\n29.0\n\n\nRegional urbanity\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n72.0\n0.0\n0.0\n28.0\n0.0\n\n\nMetropolitan urbanity\n2.0\n0.0\n0.0\n0.0\n0.0\n0.0\n1.0\n0.0\n0.0\n1.0\n0.0\n1.0\n8.0\n88.0\n0.0\n0.0\n\n\nHyper concentrated urbanity\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n100.0\n0.0\n0.0\n0.0\n\n\n\n\n\n\n\n\nimport numpy\na = numpy.array([\n    [1, 0, 0, 4, 5],\n    [2, 0, 0, 3, 5],\n    [3, 0, 0, 2, 5],\n    [4, 0, 0, 1, 5],\n    [5, 5, 5, 5, 5]\n])\nids = [f'i{i}' for i in range(len(a))]\na = pandas.DataFrame(a, index=ids, columns=ids)\nb = numpy.array([\n    [1, 0, 0, 0, 5],\n    [2, 0, 0, 0, 5],\n    [3, 0, 0, 0, 5],\n    [4, 0, 0, 0, 5],\n    [5, 5, 0, 0, 5]\n])\n\n\nfrom numba import njit\nfrom itertools import permutations\n\n@njit\ndef nscore(a):\n    ds = []\n    r = range(len(a))\n    for i in r:\n        for j in r:\n            if a[i, j] != 0:\n                ds.append(abs(i-j))\n    return numpy.array(ds).mean()\n\n@njit\ndef wnscore(a):\n    ds = []\n    r = range(len(a))\n    total = a.sum()\n    for i in r:\n        for j in r:\n            aij = a[i, j]\n            if aij != 0:\n                ds.append(abs(i-j) * aij / total)\n    return numpy.array(ds).mean()\n\ndef sorter(a, w=True):\n    if w is True:\n        scorer = wnscore\n    else:\n        scorer = nscore\n    best = None\n    best_score = numpy.inf\n    la = len(a)\n    for seq in permutations(numpy.arange(la), la):\n        score = scorer(a[seq, :][:, seq])\n        if score &lt; best_score:\n            best = seq\n            best_score = score\n    return best\n\n\ncols = [\n    #'Countryside agriculture ',\n    'Accessible suburbia ',\n    'Dense residential neighbourhoods ',\n    'Connected residential neighbourhoods ',\n    'Dense urban neighbourhoods ',\n    'Open sprawl ',\n    #'Wild countryside ',\n    'Warehouse/Park land ',\n    'Gridded residential quarters ',\n    'Urban buffer ',\n    'Disconnected suburbia ',\n    #'Local urbanity ',\n    #'Concentrated urbanity ',\n    #'Regional urbanity ',\n    #'Metropolitan urbanity ',\n    #'Hyper concentrated urbanity'\n]\ncols = [i.strip(' ') for i in cols]\nstab = tab.loc[cols, cols]\norder = sorter(stab.values, w=False)\nweighted_order = sorter(stab.values, w=True)\n\n\norder\n\n(3, 6, 1, 2, 5, 8, 0, 4, 7)\n\n\n\nweighted_order\n\n(7, 5, 4, 8, 0, 2, 1, 6, 3)\n\n\n\nrearr = (\n    ['Wild countryside', 'Countryside agriculture'] +\n    stab.columns[list(weighted_order)].tolist() +\n    [\n        'Local urbanity',\n        'Regional urbanity',\n        'Metropolitan urbanity',\n        'Concentrated urbanity',\n        'Hyper concentrated urbanity'\n    ]\n)\nrearr = [i.strip(' ') for i in rearr]\n\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nplt.rcParams['font.family'] = 'serif'\n\n\nfig, ax = plt.subplots(figsize=(8, 8))\nsns.heatmap(\n    tab.loc[rearr, rearr].round(2).replace(0, numpy.nan),\n    annot=True,\n    fmt='.0f',\n    vmax=100,\n    square=True,\n    cbar=False,\n    linewidths=.2,\n)\nax.tick_params('y',right=True, labelright=True, left=False, labelleft=False, rotation=0, labelsize=12)\nax.tick_params('x', rotation=45, labelsize=12)\nax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right', rotation_mode='anchor')\n\n[Text(0.5, 0, 'Wild countryside'),\n Text(1.5, 0, 'Countryside agriculture'),\n Text(2.5, 0, 'Urban buffer'),\n Text(3.5, 0, 'Warehouse/Park land'),\n Text(4.5, 0, 'Open sprawl'),\n Text(5.5, 0, 'Disconnected suburbia'),\n Text(6.5, 0, 'Accessible suburbia'),\n Text(7.5, 0, 'Connected residential neighbourhoods'),\n Text(8.5, 0, 'Dense residential neighbourhoods'),\n Text(9.5, 0, 'Gridded residential quarters'),\n Text(10.5, 0, 'Dense urban neighbourhoods'),\n Text(11.5, 0, 'Local urbanity'),\n Text(12.5, 0, 'Regional urbanity'),\n Text(13.5, 0, 'Metropolitan urbanity'),\n Text(14.5, 0, 'Concentrated urbanity'),\n Text(15.5, 0, 'Hyper concentrated urbanity')]"
  }
]