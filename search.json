[
  {
    "objectID": "notebooks/hilbert_split.html",
    "href": "notebooks/hilbert_split.html",
    "title": "Hilbert distance-based split into train and test",
    "section": "",
    "text": "This notebook illustrates the core of the approach to split chips into train and test used in the CEUS paper. There it was a bit more complicated than that but the principle is illustrated here.\n\nimport geopandas as gpd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom shapely import box\n\nGet only a subset of the country for illustration - NW.\n\nstart_x, start_y, end_x, end_y = (321566, 365379, 468106, 437198)\n\nLoad the data and clip them to the box defined above. The data from https://figshare.com/ndownloader/files/38736501\n\nsignatures  = gpd.read_file(\"/Users/martin/Downloads/spatial_signatures_GB_simplified.gpkg\", bbox=(start_x, start_y, end_x, end_y)).clip(box(start_x, start_y, end_x, end_y))\n\nGet coordinates of chip centroids.\n\nx_coords = np.arange(start_x, end_x, 250)\ny_coords = np.arange(start_y, end_y, 250)\nxv, yv = np.meshgrid(x_coords, y_coords)\ncombinations = np.vstack([xv.ravel(), yv.ravel()])\n\nGet chip geoemtry.\n\ngrid_cells = gpd.GeoSeries.from_xy(x=combinations[0], y=combinations[1], crs=signatures.crs).buffer(125, cap_style=3)\n\nFilter only those fully within signatures.\n\nsig_idx, grid_idx = grid_cells.sindex.query(signatures.geometry, predicate=\"contains\")\nvalid_grid_cells = grid_cells.iloc[grid_idx].to_frame('geometry')\nvalid_grid_cells[\"sig_id\"] = sig_idx\n\nGet unique signature IDs to pull from.\n\nunique = valid_grid_cells.sig_id.unique()\nunique.shape[0]\n\n745\n\n\nIllustrate the split using Hilbert distance. Chip groups with less than 20 chips are not split and should be allocated together either to train or test. The distance itself could be retrieved via GeoSeries.hilbert_distance() if needed.\n\ng = valid_grid_cells[valid_grid_cells.sig_id == unique[79]]\nif g.shape[0] &gt; 20:\n    split = np.empty(g.shape[0], dtype=int)\n    floor = int(np.floor(g.shape[0] * 0.8))\n    split[:floor] = 0\n    split[floor:] = 1\nelse:\n    split = np.ones(g.shape[0])\n\nf, ax = plt.subplots(1, 2, sharey=True)\ng.sort_values(\"geometry\").plot(split, ax=ax[0])\ng.sort_values(\"geometry\").plot(cmap=\"viridis\", ax=ax[1])\nax[0].set_title(\"split\")\nax[1].set_title(\"hilbert distance\")\n\nText(0.5, 1.0, 'hilbert distance')"
  },
  {
    "objectID": "notebooks/matrix_sorting.html",
    "href": "notebooks/matrix_sorting.html",
    "title": "Sorting based on co-occurence",
    "section": "",
    "text": "import pandas\n\nGet co-occurence table\n\n# https://urbangrammarai.xyz/spatial_signatures/esda/co-occurence.html\ntab = \"\"\"\nneighbor_type   Countryside agriculture     Accessible suburbia     Dense residential neighbourhoods    Connected residential neighbourhoods    Dense urban neighbourhoods  Open sprawl     Wild countryside    Warehouse/Park land     Gridded residential quarters    Urban buffer    Disconnected suburbia   Local urbanity  Concentrated urbanity   Regional urbanity   Metropolitan urbanity   Hyper concentrated urbanity\nCountryside agriculture     0   6   0   3   0   11  7323    181     1   14659   0   3   0   0   3   0\nAccessible suburbia     6   0   2710    3573    2   13403   6   2068    1079    4070    3423    0   0   0   0   0\nDense residential neighbourhoods    0   2710    0   4622    3457    3450    0   3632    1246    25  1600    1   0   0   0   0\nConnected residential neighbourhoods    3   3573    4622    0   1012    1222    1   2163    1939    35  1508    2   0   1   0   0\nDense urban neighbourhoods  0   2   3457    1012    0   5   0   414     443     1   52  1603    0   0   0   0\nOpen sprawl     11  13403   3450    1222    5   0   2   10383   660     14793   9521    0   0   0   0   0\nWild countryside    7323    6   0   1   0   2   0   0   2   48  0   4   0   0   1   0\nWarehouse/Park land     181     2068    3632    2163    414     10383   0   0   73  4837    3313    30  0   0   0   0\nGridded residential quarters    1   1079    1246    1939    443     660     2   73  0   16  273     133     0   0   0   0\nUrban buffer    14659   4070    25  35  1   14793   48  4837    16  0   420     3   0   0   1   0\nDisconnected suburbia   0   3423    1600    1508    52  9521    0   3313    273     420     0   0   0   1   0   0\nLocal urbanity  3   0   1   2   1603    0   4   30  133     3   0   0   0   341     1   0\nConcentrated urbanity   0   0   0   0   0   0   0   0   0   0   0   0   0   0   12  5\nRegional urbanity   0   0   0   1   0   0   0   0   0   0   1   341     0   0   133     0\nMetropolitan urbanity   3   0   0   0   0   0   1   0   0   1   0   1   12  133     0   0\nHyper concentrated urbanity     0   0   0   0   0   0   0   0   0   0   0   0   5   0   0   0\n\"\"\"\nfrom io import StringIO\ntab = pandas.read_table(StringIO(tab), index_col='neighbor_type ')\ntab = (\n    tab\n    .divide(tab.sum(axis=1), axis=0)\n    .round(2)\n    #.replace(0, numpy.nan)\n    .astype('float')\n    * 100\n)\ntab.index = [i.strip(' ') for i in tab.index]\ntab.columns =[i.strip(' ') for i in tab.columns]\n\n\ntab\n\n\n\n\n\n\n\n\nCountryside agriculture\nAccessible suburbia\nDense residential neighbourhoods\nConnected residential neighbourhoods\nDense urban neighbourhoods\nOpen sprawl\nWild countryside\nWarehouse/Park land\nGridded residential quarters\nUrban buffer\nDisconnected suburbia\nLocal urbanity\nConcentrated urbanity\nRegional urbanity\nMetropolitan urbanity\nHyper concentrated urbanity\n\n\n\n\nCountryside agriculture\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n33.0\n1.0\n0.0\n66.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\nAccessible suburbia\n0.0\n0.0\n9.0\n12.0\n0.0\n44.0\n0.0\n7.0\n4.0\n13.0\n11.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\nDense residential neighbourhoods\n0.0\n13.0\n0.0\n22.0\n17.0\n17.0\n0.0\n18.0\n6.0\n0.0\n8.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\nConnected residential neighbourhoods\n0.0\n22.0\n29.0\n0.0\n6.0\n8.0\n0.0\n13.0\n12.0\n0.0\n9.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\nDense urban neighbourhoods\n0.0\n0.0\n49.0\n14.0\n0.0\n0.0\n0.0\n6.0\n6.0\n0.0\n1.0\n23.0\n0.0\n0.0\n0.0\n0.0\n\n\nOpen sprawl\n0.0\n25.0\n6.0\n2.0\n0.0\n0.0\n0.0\n19.0\n1.0\n28.0\n18.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\nWild countryside\n99.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n1.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\nWarehouse/Park land\n1.0\n8.0\n13.0\n8.0\n2.0\n38.0\n0.0\n0.0\n0.0\n18.0\n12.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\nGridded residential quarters\n0.0\n18.0\n21.0\n33.0\n8.0\n11.0\n0.0\n1.0\n0.0\n0.0\n5.0\n2.0\n0.0\n0.0\n0.0\n0.0\n\n\nUrban buffer\n38.0\n10.0\n0.0\n0.0\n0.0\n38.0\n0.0\n12.0\n0.0\n0.0\n1.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\nDisconnected suburbia\n0.0\n17.0\n8.0\n7.0\n0.0\n47.0\n0.0\n16.0\n1.0\n2.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\nLocal urbanity\n0.0\n0.0\n0.0\n0.0\n76.0\n0.0\n0.0\n1.0\n6.0\n0.0\n0.0\n0.0\n0.0\n16.0\n0.0\n0.0\n\n\nConcentrated urbanity\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n71.0\n29.0\n\n\nRegional urbanity\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n72.0\n0.0\n0.0\n28.0\n0.0\n\n\nMetropolitan urbanity\n2.0\n0.0\n0.0\n0.0\n0.0\n0.0\n1.0\n0.0\n0.0\n1.0\n0.0\n1.0\n8.0\n88.0\n0.0\n0.0\n\n\nHyper concentrated urbanity\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n100.0\n0.0\n0.0\n0.0\n\n\n\n\n\n\n\n\nimport numpy\na = numpy.array([\n    [1, 0, 0, 4, 5],\n    [2, 0, 0, 3, 5],\n    [3, 0, 0, 2, 5],\n    [4, 0, 0, 1, 5],\n    [5, 5, 5, 5, 5]\n])\nids = [f'i{i}' for i in range(len(a))]\na = pandas.DataFrame(a, index=ids, columns=ids)\nb = numpy.array([\n    [1, 0, 0, 0, 5],\n    [2, 0, 0, 0, 5],\n    [3, 0, 0, 0, 5],\n    [4, 0, 0, 0, 5],\n    [5, 5, 0, 0, 5]\n])\n\n\nfrom numba import njit\nfrom itertools import permutations\n\n@njit\ndef nscore(a):\n    ds = []\n    r = range(len(a))\n    for i in r:\n        for j in r:\n            if a[i, j] != 0:\n                ds.append(abs(i-j))\n    return numpy.array(ds).mean()\n\n@njit\ndef wnscore(a):\n    ds = []\n    r = range(len(a))\n    total = a.sum()\n    for i in r:\n        for j in r:\n            aij = a[i, j]\n            if aij != 0:\n                ds.append(abs(i-j) * aij / total)\n    return numpy.array(ds).mean()\n\ndef sorter(a, w=True):\n    if w is True:\n        scorer = wnscore\n    else:\n        scorer = nscore\n    best = None\n    best_score = numpy.inf\n    la = len(a)\n    for seq in permutations(numpy.arange(la), la):\n        score = scorer(a[seq, :][:, seq])\n        if score &lt; best_score:\n            best = seq\n            best_score = score\n    return best\n\n\ncols = [\n    #'Countryside agriculture ',\n    'Accessible suburbia ',\n    'Dense residential neighbourhoods ',\n    'Connected residential neighbourhoods ',\n    'Dense urban neighbourhoods ',\n    'Open sprawl ',\n    #'Wild countryside ',\n    'Warehouse/Park land ',\n    'Gridded residential quarters ',\n    'Urban buffer ',\n    'Disconnected suburbia ',\n    #'Local urbanity ',\n    #'Concentrated urbanity ',\n    #'Regional urbanity ',\n    #'Metropolitan urbanity ',\n    #'Hyper concentrated urbanity'\n]\ncols = [i.strip(' ') for i in cols]\nstab = tab.loc[cols, cols]\norder = sorter(stab.values, w=False)\nweighted_order = sorter(stab.values, w=True)\n\n\norder\n\n(3, 6, 1, 2, 5, 8, 0, 4, 7)\n\n\n\nweighted_order\n\n(7, 5, 4, 8, 0, 2, 1, 6, 3)\n\n\n\nrearr = (\n    ['Wild countryside', 'Countryside agriculture'] +\n    stab.columns[list(weighted_order)].tolist() +\n    [\n        'Local urbanity',\n        'Regional urbanity',\n        'Metropolitan urbanity',\n        'Concentrated urbanity',\n        'Hyper concentrated urbanity'\n    ]\n)\nrearr = [i.strip(' ') for i in rearr]\n\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nplt.rcParams['font.family'] = 'serif'\n\n\nfig, ax = plt.subplots(figsize=(8, 8))\nsns.heatmap(\n    tab.loc[rearr, rearr].round(2).replace(0, numpy.nan),\n    annot=True,\n    fmt='.0f',\n    vmax=100,\n    square=True,\n    cbar=False,\n    linewidths=.2,\n)\nax.tick_params('y',right=True, labelright=True, left=False, labelleft=False, rotation=0, labelsize=12)\nax.tick_params('x', rotation=45, labelsize=12)\nax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right', rotation_mode='anchor')\n\n[Text(0.5, 0, 'Wild countryside'),\n Text(1.5, 0, 'Countryside agriculture'),\n Text(2.5, 0, 'Urban buffer'),\n Text(3.5, 0, 'Warehouse/Park land'),\n Text(4.5, 0, 'Open sprawl'),\n Text(5.5, 0, 'Disconnected suburbia'),\n Text(6.5, 0, 'Accessible suburbia'),\n Text(7.5, 0, 'Connected residential neighbourhoods'),\n Text(8.5, 0, 'Dense residential neighbourhoods'),\n Text(9.5, 0, 'Gridded residential quarters'),\n Text(10.5, 0, 'Dense urban neighbourhoods'),\n Text(11.5, 0, 'Local urbanity'),\n Text(12.5, 0, 'Regional urbanity'),\n Text(13.5, 0, 'Metropolitan urbanity'),\n Text(14.5, 0, 'Concentrated urbanity'),\n Text(15.5, 0, 'Hyper concentrated urbanity')]"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "EuroFab research project",
    "section": "",
    "text": "The landing page of the EuroFab project."
  },
  {
    "objectID": "notebooks/hello.html",
    "href": "notebooks/hello.html",
    "title": "Example notebook",
    "section": "",
    "text": "These should not be executed by Quarto.\n\nimport geopandas\n\ngeopandas.show_versions()\n\n\nSYSTEM INFO\n-----------\npython     : 3.11.4 | packaged by conda-forge | (main, Jun 10 2023, 18:08:41) [Clang 15.0.7 ]\nexecutable : /Users/martin/miniforge3/envs/stable/bin/python\nmachine    : macOS-14.5-arm64-arm-64bit\n\nGEOS, GDAL, PROJ INFO\n---------------------\nGEOS       : 3.12.1\nGEOS lib   : None\nGDAL       : 3.7.3\nGDAL data dir: /Users/martin/miniforge3/envs/stable/share/gdal\nPROJ       : 9.3.0\nPROJ data dir: /Users/martin/miniforge3/envs/stable/share/proj\n\nPYTHON DEPENDENCIES\n-------------------\ngeopandas  : 0.14.4\nnumpy      : 1.26.4\npandas     : 2.2.2\npyproj     : 3.6.1\nshapely    : 2.0.4\nfiona      : 1.9.5\ngeoalchemy2: None\ngeopy      : 2.4.1\nmatplotlib : 3.8.4\nmapclassify: 2.6.1\npygeos     : None\npyogrio    : 0.7.2\npsycopg2   : None\npyarrow    : 16.1.0\nrtree      : 1.2.0",
    "crumbs": [
      "Notebooks",
      "Example notebook"
    ]
  },
  {
    "objectID": "notebooks/run_pipeline.html",
    "href": "notebooks/run_pipeline.html",
    "title": "Earth observation | EuroFab",
    "section": "",
    "text": "import sys\nsys.path.insert(1, '/bask/homes/f/fedu7800/vjgo8416-demoland/spatial_signatures/eo/ai_pipeline')\n\nimport pipeline\nfrom pipeline import GeoTileDataset, read_data, plot_examples\n\nfrom torch.utils.data import Dataset, DataLoader\nimport matplotlib.pyplot as plt\nimport geopandas as gpd\n\n%matplotlib inline\n\n\ngeojson_path = '/bask/homes/f/fedu7800/vjgo8416-demoland/spatial_signatures/london_25_25_grid_clipped.geojson'\nvrt_file = '/bask/homes/f/fedu7800/vjgo8416-demoland/satellite_demoland/data/mosaic_cube/vrt_allbands/2017_combined.vrt'\n\n\ndataset, dataloader = read_data(geojson_path, vrt_file)\n\n\nplot_examples(dataset, num_examples=3)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Run the pipeline\npipeline.spatial_sig_prediction(\n    geo_path= \"/bask/homes/f/fedu7800/vjgo8416-demoland/spatial_signatures/london_25_25_grid_clipped.geojson\",\n    vrt_file= \"/bask/homes/f/fedu7800/vjgo8416-demoland/satellite_demoland/data/mosaic_cube/vrt_allbands/2017_combined.vrt\",\n    xgb_weights = \"/bask/homes/f/fedu7800/vjgo8416-demoland/spatial_signatures/predictions/xgb_model_25_latlonh6_jan25_weighted.bin\",\n    model_weights = \"/bask/homes/f/fedu7800/vjgo8416-demoland/satellite_demoland/models/satlas/weights/satlas-model-v1-lowres.pth\",\n    output_path= \"/bask/homes/f/fedu7800/vjgo8416-demoland/satellite_demoland/data/test.parquet\"\n)\n\n/bask/homes/f/fedu7800/vjgo8416-demoland/spatial_signatures/eo/ai_pipeline/pipeline.py:122: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  full_state_dict = torch.load(model_weights_path, map_location=device)\n\n\n\ntest = gpd.read_parquet('/bask/homes/f/fedu7800/vjgo8416-demoland/satellite_demoland/data//test.parquet')\n\n\nclass_labels = {\n    'Accessible suburbia': 0,\n    'Connected residential neighbourhoods': 1,\n    'Countryside agriculture': 2,\n    'Dense residential neighbourhoods': 3,\n    'Dense urban neighbourhoods': 4,\n    'Disconnected suburbia': 5,\n    'Gridded residential quarters': 6,\n    'Open sprawl': 7,\n    'Urban buffer': 8,\n    'Urbanity': 9,\n    'Warehouse/Park land': 10,\n    'Wild countryside': 11\n}\n\n\ntest['class'] = test['prediction'].map({v: k for k, v in class_labels.items()})\n\n\ntest.explore(column='class', cmap='Accent')\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook"
  }
]